{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 2\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_test_wan.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imHog_list = []\n",
    "im_flt = []\n",
    "\n",
    "with open(r'C:\\Users\\ww6848\\Documents\\Springboard\\capstone project 2\\title.txt') as f:\n",
    "    nn = f.readlines()\n",
    "    names = [x.strip() for x in nn] \n",
    "\n",
    "num = 0    \n",
    "for name in names:\n",
    "    img = cv2.imread(r'C:\\Users\\ww6848\\Documents\\Springboard\\capstone project 2\\natural_images\\test\\\\'+name)\n",
    "    #wwww = r'C:\\Users\\ww6848\\Documents\\Springboard\\capstone project 2\\natural_images\\airplane\\\\'+name\n",
    "\n",
    "\n",
    "    fd = img.flatten()\n",
    "    im_flt.append(fd)\n",
    "    imHog_list.append(img)\n",
    "    num = num + 1\n",
    "\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.zeros((len(names),1))\n",
    "with open(r'C:\\Users\\ww6848\\Documents\\Springboard\\capstone project 2\\value.txt') as f:\n",
    "    vals = f.readlines()\n",
    "    vals = [x.strip() for x in vals] \n",
    "k = 0 \n",
    "for val in vals:\n",
    "    label_array[k,0] = val\n",
    "    k = k+1\n",
    "   \n",
    "im_array = np.asarray(imHog_list)\n",
    "im_flt_arr = np.asarray(im_flt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (140, 1)\n",
      "x_train shape: (140, 100, 100, 3)\n",
      "Xraw shape: (200, 100, 100, 3)\n",
      "yraw shape: (200, 1)\n"
     ]
    }
   ],
   "source": [
    "# assign variables to X and y\n",
    "Xraw = im_array\n",
    "yraw = label_array\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xraw, yraw, test_size=0.3, random_state=42)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Xraw shape:', Xraw.shape)\n",
    "print('yraw shape:', yraw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (140, 2)\n",
      "y_test shape: (60, 2)\n"
     ]
    }
   ],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ww6848\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ww6848\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# #########add a new layer####################\n",
    "# model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "#######################################################\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:From C:\\Users\\ww6848\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 8.3041 - acc: 0.4634 - val_loss: 6.7849 - val_acc: 0.5667\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 6.8860 - acc: 0.5622 - val_loss: 8.0221 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 7.4031 - acc: 0.5274 - val_loss: 3.8605 - val_acc: 0.7333\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 4.1261 - acc: 0.7285 - val_loss: 3.3815 - val_acc: 0.7833\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.8518 - acc: 0.7203 - val_loss: 3.1648 - val_acc: 0.7667\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.3596 - acc: 0.7824 - val_loss: 0.3789 - val_acc: 0.9667\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.6068 - acc: 0.8272 - val_loss: 3.5059 - val_acc: 0.7667\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.1584 - acc: 0.8569 - val_loss: 0.3408 - val_acc: 0.9667\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 2.3245 - acc: 0.8464 - val_loss: 1.4375 - val_acc: 0.9000\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.3107 - acc: 0.7651 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.5969 - acc: 0.8291 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.7739 - acc: 0.8761 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.6191 - acc: 0.8355 - val_loss: 1.7248 - val_acc: 0.8833\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.8606 - acc: 0.8720 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.3095 - acc: 0.8460 - val_loss: 2.3461 - val_acc: 0.8333\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.0531 - acc: 0.8569 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.2175 - acc: 0.9187 - val_loss: 2.9052e-04 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.5528 - acc: 0.8867 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.8869 - acc: 0.8697 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2121 - acc: 0.9209 - val_loss: 1.7639 - val_acc: 0.8833\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 2.4149 - acc: 0.8419 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.3810 - acc: 0.9145 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.6014 - acc: 0.8953 - val_loss: 1.0952 - val_acc: 0.9167\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.7523 - acc: 0.8825 - val_loss: 1.3411e-06 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.3071 - acc: 0.9145 - val_loss: 1.3025 - val_acc: 0.8833\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 2.0521 - acc: 0.8633 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.9604 - acc: 0.8633 - val_loss: 1.0347e-04 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.5264 - acc: 0.8995 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.0114 - acc: 0.9296 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.5318 - acc: 0.9017 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.7469 - acc: 0.8908 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.0202 - acc: 0.8716 - val_loss: 0.5654 - val_acc: 0.9500\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.2238 - acc: 0.9187 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 2.2981 - acc: 0.8377 - val_loss: 2.2074 - val_acc: 0.8500\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2773 - acc: 0.9081 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7275 - acc: 0.9488 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.3436 - acc: 0.9040 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6651 - acc: 0.9552 - val_loss: 1.3588 - val_acc: 0.9000\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.4627 - acc: 0.8912 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.2097 - acc: 0.8547 - val_loss: 0.5977 - val_acc: 0.9500\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.5338 - acc: 0.8931 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9297 - acc: 0.9424 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.4656 - acc: 0.9059 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.8971 - acc: 0.8784 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.0253 - acc: 0.9273 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.5860 - acc: 0.8953 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7158 - acc: 0.9552 - val_loss: 0.2717 - val_acc: 0.9833\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.8960 - acc: 0.9424 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.0496 - acc: 0.9296 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.0623 - acc: 0.9250 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7334 - acc: 0.9488 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2083 - acc: 0.9250 - val_loss: 2.2808e-05 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.4807 - acc: 0.9081 - val_loss: 2.2867e-05 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.7010 - acc: 0.9552 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.0282 - acc: 0.9273 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.3820 - acc: 0.9040 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.8216 - acc: 0.9465 - val_loss: 0.0295 - val_acc: 0.9833\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.8252 - acc: 0.9488 - val_loss: 3.8082e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6296 - acc: 0.9552 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.3821 - acc: 0.9123 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.1952 - acc: 0.8611 - val_loss: 1.1607 - val_acc: 0.9167\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.5231 - acc: 0.9040 - val_loss: 0.2211 - val_acc: 0.9833\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.4807 - acc: 0.9081 - val_loss: 0.2211 - val_acc: 0.9833\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.4145 - acc: 0.9123 - val_loss: 0.0295 - val_acc: 0.9833\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.0622 - acc: 0.9337 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.1168 - acc: 0.9187 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.2536 - acc: 0.9145 - val_loss: 0.1777 - val_acc: 0.9833\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2744 - acc: 0.9209 - val_loss: 0.1777 - val_acc: 0.9833\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2314 - acc: 0.9168 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.8210 - acc: 0.8780 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.1522 - acc: 0.9232 - val_loss: 1.2668 - val_acc: 0.9167\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2123 - acc: 0.9081 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9525 - acc: 0.9314 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.7955 - acc: 0.9506 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.6102 - acc: 0.8908 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.5315 - acc: 0.9616 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3490 - acc: 0.9785 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6188 - acc: 0.9616 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.8251 - acc: 0.9488 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.4134 - acc: 0.9081 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.2889 - acc: 0.9081 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.0036 - acc: 0.9378 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.1484 - acc: 0.9145 - val_loss: 0.8291 - val_acc: 0.9333\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.8086 - acc: 0.9424 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.1713 - acc: 0.9273 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.7121 - acc: 0.9424 - val_loss: 0.0535 - val_acc: 0.9833\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9653 - acc: 0.9401 - val_loss: 1.2716e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.6188 - acc: 0.9616 - val_loss: 1.2716e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9106 - acc: 0.9424 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.8990 - acc: 0.9424 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.1417 - acc: 0.9292 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.8492 - acc: 0.9424 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7895 - acc: 0.9424 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.4803 - acc: 0.9680 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.9650 - acc: 0.9401 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.2081 - acc: 0.9250 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7587 - acc: 0.9529 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7484 - acc: 0.9529 - val_loss: 2.2695 - val_acc: 0.8500\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.7369 - acc: 0.7651 - val_loss: 3.9596 - val_acc: 0.7500\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 2.6698 - acc: 0.8336 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "{'val_loss': [6.784938907623291, 8.022094345092773, 3.860513687133789, 3.38146835565567, 3.1648345232009887, 0.37886516425787703, 3.505886459350586, 0.34077994911858694, 1.4375396966934204, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.2686350107192993, 1.724780297279358, 1.1920928955078125e-07, 2.3460926532745363, 1.1920928955078125e-07, 0.00029052409809082747, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.7638701915740966, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.0952264070510864, 1.3411495274340268e-06, 1.3025074869394302, 1.1920928955078125e-07, 0.00010346759809181094, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.2686350107192993, 0.5654162650374929, 1.1920928955078125e-07, 2.207416296005249, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.358757644891739, 1.1920928955078125e-07, 0.5976826522499323, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.2686350107192993, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.27171960572441095, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 2.280825428897515e-05, 2.28669450734742e-05, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.029472574591636658, 0.00038081773091107606, 0.2686350107192993, 1.1920928955078125e-07, 1.1606950521469117, 0.22107396125793458, 0.22107396125793458, 0.029543110728263856, 0.2686350107192993, 0.2686350107192993, 0.17769980430603027, 0.1776801109313965, 1.1920928955078125e-07, 0.2686350107192993, 1.2668362379074096, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.2686350107192993, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.2686350107192993, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.8291237056255341, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.05353937745094299, 1.271565793103946e-07, 1.271565793103946e-07, 1.1920928955078125e-07, 0.2686350107192993, 0.2686350107192993, 1.1920928955078125e-07, 1.1920928955078125e-07, 0.2686350107192993, 0.2686350107192993, 0.2686350107192993, 0.2686350107192993, 2.269525241851807, 3.959556722640991, 0.2686484062855016], 'val_acc': [0.5666666567325592, 0.49999999403953554, 0.7333333373069764, 0.7833333373069763, 0.7666666626930236, 0.9666666746139526, 0.7666666626930236, 0.9666666746139526, 0.9, 1.0, 1.0, 0.9833333373069764, 0.8833333373069763, 1.0, 0.8333333373069763, 1.0, 1.0, 1.0, 1.0, 0.8833333373069763, 1.0, 1.0, 0.9166666746139527, 1.0, 0.8833333373069763, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9833333373069764, 0.95, 1.0, 0.85, 1.0, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 1.0, 0.9833333373069764, 1.0, 1.0, 1.0, 0.9833333373069764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9833333373069764, 1.0, 0.9833333373069764, 1.0, 0.9166666746139527, 0.9833333373069764, 0.9833333373069764, 0.9833333373069764, 0.9833333373069764, 0.9833333373069764, 0.9833333373069764, 0.9833333373069764, 1.0, 0.9833333373069764, 0.9166666746139527, 1.0, 1.0, 1.0, 0.9833333373069764, 1.0, 1.0, 1.0, 1.0, 0.9833333373069764, 1.0, 1.0, 0.9333333373069763, 1.0, 1.0, 0.9833333373069764, 1.0, 1.0, 1.0, 0.9833333373069764, 0.9833333373069764, 1.0, 1.0, 0.9833333373069764, 0.9833333373069764, 0.9833333373069764, 0.9833333373069764, 0.85, 0.7499999880790711, 0.9833333373069764], 'loss': [8.020256778172085, 7.0619609151567735, 7.151883452279227, 4.064404787336077, 3.9873310565948485, 3.7502130883080618, 2.9099501667400807, 2.253140582357134, 2.594769024848938, 3.4874381712504796, 2.5865062509264263, 1.8240384067807878, 2.6112328733716694, 2.0769667863845824, 2.1094538007463726, 2.1356287240982055, 1.0466689859117781, 1.5670241389955792, 1.950174559865679, 1.1963766404560634, 2.3833298001970564, 1.3854255505970545, 1.653357686315264, 1.7998432670320783, 1.3028798205511911, 2.1344784838812694, 2.0810992019517083, 1.3915353298187256, 1.1289513417652675, 1.5537718330110823, 1.4814965794894046, 1.7865559986659458, 1.0536969218935286, 2.40908682346344, 1.2696693079812187, 0.8120899166379656, 1.4998146840504238, 0.742391882623945, 1.6327578101839337, 2.154284279687064, 1.3998364107949393, 1.03784202507564, 1.3236613477979386, 2.1177076986857823, 0.9883529492786952, 1.613642624446324, 0.7990831068583897, 1.0002167422091588, 1.1716678210667884, 0.9068189416612897, 0.8186263050351824, 1.0364093053553785, 1.4966803107942854, 0.78250298840659, 0.9860503160527774, 1.542672426359994, 0.7608995403562273, 0.9211906463439975, 0.7028498344189886, 1.2304225172315324, 2.138069118772234, 1.7002117531640188, 1.4966803107942854, 1.2666491985321044, 1.029509391103472, 1.0592643790612264, 1.2431619882583618, 1.2664217914853777, 1.374614187649318, 1.5641460827418736, 1.2861396074295044, 1.1970885585660913, 0.7508400235857282, 0.5756463255201067, 1.3947534901755196, 0.5933178050177438, 0.23336198670523509, 0.6907755545207432, 0.9210340602057321, 1.4177259036472865, 1.2825583560126168, 0.8067547116960798, 1.211069621358599, 0.9026369060788836, 1.1512925250189645, 0.794948513167245, 0.9213338681629726, 0.6907755545207432, 1.0164918865476336, 1.0035484007426672, 0.8059048524925142, 0.9479475123541695, 0.8813050099781581, 0.5361849205834525, 0.9210557086127145, 1.0361633368900844, 0.6907756362642561, 0.6792686330425828, 3.8590209892817904, 2.980224360738482], 'acc': [0.4785714294229235, 0.5500000017029899, 0.5500000008514949, 0.7357142874172755, 0.7071428554398673, 0.7571428571428571, 0.8071428571428572, 0.8500000017029898, 0.8285714285714286, 0.7571428554398673, 0.8285714268684388, 0.8714285731315613, 0.8357142840112959, 0.8571428571428571, 0.8571428571428571, 0.8500000017029898, 0.9285714268684387, 0.892857141154153, 0.8642857159887042, 0.9214285731315612, 0.842857141154153, 0.9142857159887041, 0.8928571445601327, 0.8785714302744184, 0.9142857159887041, 0.857142858845847, 0.857142858845847, 0.9071428554398673, 0.9214285714285714, 0.9000000017029899, 0.9071428571428571, 0.8857142857142857, 0.9285714268684387, 0.8285714302744184, 0.907142858845847, 0.9428571428571428, 0.8928571428571429, 0.95, 0.8785714285714286, 0.8571428554398673, 0.8999999982970102, 0.9357142857142857, 0.9142857125827244, 0.8642857142857143, 0.9285714302744185, 0.8928571445601327, 0.95, 0.9357142857142857, 0.9214285714285714, 0.9357142840112959, 0.9428571428571428, 0.9357142840112959, 0.907142858845847, 0.95, 0.9285714302744185, 0.8928571428571429, 0.9500000017029898, 0.9428571428571428, 0.95, 0.9214285697255816, 0.8642857125827245, 0.8928571428571429, 0.907142858845847, 0.9214285697255816, 0.9357142874172756, 0.9285714268684387, 0.9142857159887041, 0.9214285731315612, 0.9071428571428571, 0.8928571428571429, 0.9142857142857143, 0.907142858845847, 0.942857141154153, 0.9642857125827244, 0.9071428571428571, 0.9571428571428572, 0.9857142874172755, 0.9571428571428572, 0.9428571428571428, 0.907142858845847, 0.907142858845847, 0.9499999982970101, 0.9142857159887041, 0.9357142857142857, 0.9285714302744185, 0.9357142857142857, 0.9428571445601327, 0.9571428571428572, 0.9357142857142857, 0.9357142857142857, 0.95, 0.9357142857142857, 0.9357142857142857, 0.9642857142857143, 0.9428571445601327, 0.9357142840112959, 0.957142858845847, 0.957142858845847, 0.7571428554398673, 0.8142857142857143]}\n"
     ]
    }
   ],
   "source": [
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    hist = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "    print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\ww6848\\Documents\\Springboard\\capstone project 2\\saved_models\\keras_test_wan.h5 \n",
      "60/60 [==============================] - 1s 11ms/step\n",
      "Test loss: 0.2686484182069156\n",
      "Test accuracy: 0.9833333412806193\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_classes shape: (60, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = keras.utils.to_categorical(y_pred_classes, num_classes)\n",
    "print('y_pred_classes shape:', y_pred_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_pred_classes = [ np.where(r==1)[0][0] for r in y_pred_classes ]\n",
    "yy_test = [ np.where(r==1)[0][0] for r in y_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADhxJREFUeJzt3X+M1/V9wPHniwMPpp6wiAxBwakodANkjrgxtcPN3QwVMjVOk8Z1prepNVpd125NbFj6x34pbaI2XotgMnvq6IxycXZms0Hj1KJFqx4Vf7QTtLP8UHAF5O5e+4Ov5oLfu+/9et8X7p6P5Jvc9/P9fN6fN+HyvDef732+RGYiSSpnXL0nIEmjnaGVpMIMrSQVZmglqTBDK0mFGVpJKszQSlJhhlaSCjO0klTY+NInaG9v99YzfcL643bXewo6DN117pUx1DEG0pxly5YN+Xz94YpWkgoztJJUmKGVpMIMrSRVERETI+LZiHghIl6OiJWV7adExDMRsSUi7o+Io2qNZWglqbr9wNLMXAAsBJoj4hzgH4BVmXk6sAu4utZAhlaSqsiDPqg8nVB5JLAUWFfZfg+wotZYhlbSmBURLRGxscej5ZDXGyJiE/Au8BjwOvBeZnZWdtkKzKh1nuK/RytJh6vMbAVa+3i9C1gYEZOBB4G51XardR5XtJJUQ2a+B/wAOAeYHBEfLVJnAm/XOt7QSlIVETG1spIlIiYBfwB0AI8Dl1Z2uwp4qNZYXjqQpOqmA/dERAMHF6UPZGZ7RLwC3BcRXwd+BKyuNZChlaQqMvNF4Kwq298AFg9kLC8dSFJhhlaSCjO0klSYoZWkwgytJBVmaCWpMEMrSYUZWkkqzNBKUmGGVpIKM7SSVJihlaTCDK0kFWZoJakwQytJhfl5tJJGlUVTflbvKXyCK1pJKszQSlJhhlaSCjO0klSYoZWkwgytJBVmaCWpMEMrSYUZWkkqzNBKUmGGVpIKM7SSVJihlaTCDK0kFWZoJakwQytJhRlaSSrM0EpSFRFxUkQ8HhEdEfFyRNxwyOt/FREZEcfXGsv/ykaSqusEbs7M5yPiWOC5iHgsM1+JiJOAPwT+pz8DuaKVpCoy853MfL7y9R6gA5hReXkV8NdA9mcsQytpzIqIlojY2OPR0st+s4GzgGci4mJgW2a+0N/zeOmgkAMHDnDHHXfQ2dlJd3c38+fPp7m5mSeffJINGzawY8cOVq5cyTHHHFPvqaqOdrz0Gq+1PUp2dzP93EXMuuj36j2lMSUzW4HWvvaJiGOA7wE3cvBywleBCwdyHkNbyPjx47nmmmtobGykq6uL22+/nblz5zJ79mzmzZvHnXfeWe8pqs6yu5st9z7Cgps+S+OUJp77+rc5fuEZHH3i1HpPTRURMYGDkb03M/8tIn4TOAV4ISIAZgLPR8TizPx5b+PUDG1EnAks5+C1iQTeBh7OzI6h/zFGr4igsbERgK6uLrq6ugCYOXNmPaelw8juN7cx6YRfZdLUKQCcsPhTbN+02dAeJuJgSVcDHZl5G0Bm/hg4occ+PwXOzsztfY3VZ2gj4svAFcB9wLOVzTOBtoi4LzP/frB/iLGgu7ubVatWsX37dpYsWcKsWbPqPSUdRvbv2kPjlKaPnzdOaWL3G9vqOCMdYgnwWeDHEbGpsu1vM/ORgQ5Ua0V7NfCpzDzQc2NE3Aa8DBjaPowbN46bb76ZvXv3smbNGt555x2mT59e72npsPHJN6wP/mtUh4PMfBLo828kM2f3Z6xaoe0GTgR+dsj26ZXXqqq8c9cCcN1119Hc3NyfuYxakyZN4tRTT2Xz5s2GVh9rnNLE/l27P36+f9dujpp8bB1nNDqcOPXbA9j7umLz6KlWaG8E/jMitgBvVbadDJwGfKG3g3q+k9fe3t6v3zMbbT744AMaGhqYNGkSBw4cYMuWLSxdurTe09Jh5NjZM9j7vzvY+4tdNE5p4t1nX2be5/+k3tNSAX2GNjMfjYg5wGIOvhkWwFbgh5nZNQLzO2Lt3r2btrY2MpPMZMGCBcybN48nnniCxx9/nD179nDrrbdy5plncvnll9d7uqqDcQ3jOP3Ki3jxG/9CdifTlyzk6Bkn1D5QR5zILLvgHKsrWvVt/XG7a++kMeeuc68c+lXqVxf2vzlzNo3IVXHvDJOkwgytJBVmaCWpMEMrSYUZWkkqzNBKUmGGVpIKM7SSVJihlaTCDK0kFWZoJakwQytJhRlaSSrM0EpSYYZWkgoztJJUmKGVpMIMrSQVZmglqTBDK0mFGVpJKszQSlJhhlaSChtf7wlI0nBqy9P7ve8VBefRkytaSSrM0EpSYYZWkgoztJJUmKGVpMIMrST1IiLujoh3I+KlHtsWRsTTEbEpIjZGxOJa4xhaSerdWqD5kG3/CKzMzIXALZXnfTK0ktSLzNwA7Dx0M9BU+fo44O1a43jDgiQNzI3A9yPinzm4WP3dWge4opU0ZkVES+U660ePln4cdg3wxcw8CfgisLrWAa5oJY1ZmdkKtA7wsKuAGypf/yvwnVoHuKKVpIF5Gzi/8vVSYEutA1zRSlIvIqIN+DRwfERsBb4GfB74ZkSMB/YBNS83GFpJ6kVm9vYBX781kHG8dCBJhRlaSSrM0EpSYYZWkgoztJJUmKGVpMIMrSQVZmglqTBDK0mFGVpJKszQSlJhhlaSCiv+oTLrj9td+hQ6An3m/abaO0mjhJ/eJWlU+f2Hb6i900e+VG4ePXnpQJIKM7SSVJihlaTCDK0kFWZoJakwQytJhRlaSSrM0EpSYYZWkgoztJJUmKGVpMIMrSQVZmglqTBDK0mFGVpJKszQSlJhhlaSCjO0klSYoZWkwgytJPUiIu6OiHcj4qUe2/4pIjZHxIsR8WBETK41jqGVpN6tBZoP2fYY8BuZOR94FfibWoMYWknqRWZuAHYesu0/MrOz8vRpYGatcQytJA3enwP/XmsnQytpzIqIlojY2OPRMoBjvwp0AvfW2nf8UCYpSUeyzGwFWgd6XERcBSwDLsjMrLW/oZWkAYiIZuDLwPmZ+cv+HGNoJY0q3z1hYr/3vanG6xHRBnwaOD4itgJf4+BvGTQCj0UEwNOZ+Zd9jWNoJakXmXlFlc2rBzqOb4ZJUmGGVpIKM7SSVJihlaTCDK0kFWZoJakwQytJhRlaSSrM0EpSYYZWkgoztJJUmKGVpMIMrSQVZmglqTBDK0mFGVpJKszQSlJhhlaSCjO0klSYoZWkwvzPGUfA5jUPsePFV5lw7NEs/rtr6z0d1dGuXbtoa2tjz549RATnnHMO5513Htu2bWPdunV0dnYybtw4LrnkEk4++eR6T1fDxNCOgF9bspAZSxfTsfrBek9FddbQ0MDFF1/MzJkz2bdvH6tWrWLOnDm0t7dz4YUXMnfuXDo6Omhvb+faa/2hPFoY2hEwec4s9m5/r97T0GGgqamJpqYmACZOnMi0adN4//33Adi3bx8Ae/fu/XgfjQ6DDm1EfC4z1wznZKSxZOfOnWzbto1Zs2axYsUKWltbWb9+PZnJ9ddfX+/paRgN5c2wlb29EBEtEbExIjZ2PPxfQziFNDrt37+fe+65h+XLlzNx4kSeeuopli9fzi233MLy5ct54IEH6j1FDaM+V7QR8WJvLwHTejsuM1uBVoC/eOK7OejZSaNQV1cXa9euZdGiRcyfPx+AjRs3smLFCgAWLFhgaIfghh3fGsDeq4vNo6dalw6mAX8E7DpkewBPFZmRNIplJvfffz/Tpk3j/PPP/3h7U1MTr7/+Oqeddhpbtmxh6tSpdZylhlut0LYDx2TmpkNfiIgfFJnRKPRK6/d47yc/5cAHv+SpL93GKRd/munnLqr3tFQHb775Js899xzTp0/n1ltvBeCiiy7isssu46GHHqKrq4sJEyZw6aWX1nmmGk6RWfZf9l46UDWfed931fVJy5Yti6GO0XXb1f1uTsNNq4d8vv7wzjBJKszQSlJhhlaSCjO0klSYoZWkXkTE5IhYFxGbI6IjIn5nMOP4WQeS1LtvAo9m5qURcRTwK4MZxNBKUhUR0QScB/wZQGZ+CHw4mLG8dCBJ1f068AtgTUT8KCK+ExFHD2YgQytpzOr5AViVR0uPl8cDi4BvZeZZwP8BXxnMebx0IGnM6vkBWFVsBbZm5jOV5+sYZGhd0UpSFZn5c+CtiDijsukC4JXBjOWKVpJ6dz1wb+U3Dt4APjeYQQytJPWi8smFZw91HC8dSFJhhlaSCjO0klSYoZWkwgytJBVmaCWpMEMrSYUZWkkqzNBKUmGGVpIK8xZcSaPKtb99Qb/3vavgPHpyRStJhRlaSSrM0EpSYYZWkgoztJJUmKGVpMIMrSQVZmglqTBDK0mFGVpJKszQSlJhhlaSCjO0klSYoZWkwgytJBVmaCWpMEMrSYUZWkkqzNBKUmGGVpIKM7SSVJihlaTCDK0k9SIimiPiJxHxWkR8ZbDjGFpJqiIiGoA7gD8G5gFXRMS8wYxlaCWpusXAa5n5RmZ+CNwHLB/MQIZWkqqbAbzV4/nWyrYBGz8s0+nDXedeGaXPcaSIiJbMbK33PHR48ftieA2kORHRArT02NTa4++i2jg5mDm5oh1ZLbV30Rjk90WdZGZrZp7d49HzB95W4KQez2cCbw/mPIZWkqr7IXB6RJwSEUcBfwo8PJiBil86kKQjUWZ2RsQXgO8DDcDdmfnyYMYytCPL63Cqxu+Lw1RmPgI8MtRxInNQ13YlSf3kNVpJKszQjpDhupVPo0dE3B0R70bES/Wei8oytCNgOG/l06iyFmiu9yRUnqEdGcN2K59Gj8zcAOys9zxUnqEdGcN2K5+kI4+hHRnDdiufpCOPoR0Zw3Yrn6Qjj6EdGcN2K5+kI4+hHQGZ2Ql8dCtfB/DAYG/l0+gREW3AfwNnRMTWiLi63nNSGd4ZJkmFuaKVpMIMrSQVZmglqTBDK0mFGVpJKszQSlJhhlaSCjO0klTY/wNZnz7aiUlJawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the validation confusion matrix\n",
    "cm = confusion_matrix(yy_test, yy_pred_classes)\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            cmap=\"Set2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
